use "compiler/ast.ae"
use "compiler/lexer.ae"
use "compiler/utils.ae"

// Don't think this is used enough to include in the prelude.
@compiler c_include "libgen.h"
def dirname(path: string): string extern

struct ParserContext {
    tokens: &Vector  // &Vector<Token>
    offset: i32
}

def ParserContext::new(tokens: &Vector, offset: i32): &ParserContext {
    let context = calloc(1, sizeof(ParserContext)) as &ParserContext
    *context = ParserContext(tokens, offset)
    return context
}

struct Parser {
    // Current context
    tokens: &Vector  // &Vector<Token>
    curr: i32

    // Parser context stack
    context_stack: &Vector
    project_root: string
    include_dirs: &Vector

    program: &Program
}

// We take in the filename to figure out the project root
def Parser::new(filename: string): &Parser {
    let parser = calloc(1, sizeof(Parser)) as &Parser

    parser.include_dirs = Vector::new()
    parser.add_include_dir(".")

    // This is because different `dirname` implementations have different
    // memory semantics, and we don't want to ever mutate the filename.
    let tmp_filename = filename.copy()
    parser.project_root = dirname(tmp_filename).copy()
    free(tmp_filename)

    let aecor_root = get_environment_variable("AECOR_ROOT")
    if aecor_root? {
        parser.add_include_dir(aecor_root)
    }

    parser.context_stack = Vector::new()
    return parser
}

def Parser::push_context(&this, tokens: &Vector) {
    let cur_context = ParserContext::new(.tokens, .curr)
    .context_stack.push(cur_context)

    .tokens = tokens
    .curr = 0
}

def Parser::pop_context(&this) {
    let cur_context = .context_stack.pop() as &ParserContext
    .tokens = cur_context.tokens
    .curr = cur_context.offset
    free(cur_context)
}

def Parser::add_include_dir(&this, dir: string) {
    .include_dirs.push(dir)
}

def Parser::error_msg(&this, msg: string): &Error {
    let err = Error::new(.token().span, msg)
    .program.errors.push(err)
    return err
}

def Parser::error(&this, err: &Error) {
    .program.errors.push(err)
}

def Parser::unhandled_type(&this, func: string) {
    .error_msg(`Unexpected token in {func}: {.token().type.str()}`)
}

def Parser::token(&this): &Token => .tokens.at(.curr)

def Parser::token_is(&this, type: TokenType): bool {
    if type == TokenType::Newline {
        return .token().seen_newline
    }
    return .token().type == type
}

def Parser::consume_if(&this, type: TokenType): bool {
    if .token_is(type) {
        // Newline tokens are special because they don't consume a token.
        if type != TokenType::Newline {
            .curr += 1
        }
        return true
    }
    return false
}

def Parser::consume_newline_or(&this, type: TokenType) {
    if .token_is(type) {
        .curr += 1
    } else if not .token().seen_newline {
        .error_msg(`Expected {type.str()} or newline`).panic()
    }
}

def Parser::consume(&this, type: TokenType): &Token {
    let tok = .token()
    if not .consume_if(type) {
        .error_msg(`Expected TokenType::{type.str()}`).panic()
    }
    return tok
}

def Parser::parse_type_with_parent(&this, parent: &Type): &Type {
    let type = null as &Type
    let span = .token().span

    match .token().type {
        TokenType::Ampersand => {
            type = Type::new(BaseType::Pointer, .consume(TokenType::Ampersand).span)
            .parse_type_with_parent(type)
        }
        TokenType::Bool => type = Type::new(BaseType::Bool, .consume(TokenType::Bool).span)
        TokenType::Char => type = Type::new(BaseType::Char, .consume(TokenType::Char).span)

        TokenType::I8 => type = Type::new(BaseType::I8, .consume(TokenType::I8).span)
        TokenType::I16 => type = Type::new(BaseType::I16, .consume(TokenType::I16).span)
        TokenType::I32 => type = Type::new(BaseType::I32, .consume(TokenType::I32).span)
        TokenType::I64 => type = Type::new(BaseType::I64, .consume(TokenType::I64).span)

        TokenType::U8 => type = Type::new(BaseType::U8, .consume(TokenType::U8).span)
        TokenType::U16 => type = Type::new(BaseType::U16, .consume(TokenType::U16).span)
        TokenType::U32 => type = Type::new(BaseType::U32, .consume(TokenType::U32).span)
        TokenType::U64 => type = Type::new(BaseType::U64, .consume(TokenType::U64).span)

        TokenType::F32 => type = Type::new(BaseType::F32, .consume(TokenType::F32).span)
        TokenType::F64 => type = Type::new(BaseType::F64, .consume(TokenType::F64).span)

        TokenType::UntypedPtr => type = Type::ptr_to(BaseType::Void, .consume(TokenType::UntypedPtr).span)
        TokenType::String => {
            type = Type::ptr_to(BaseType::Char, .consume(TokenType::String).span)
            type.ptr.name = "string"
        }
        TokenType::Identifier => {
            type = Type::new(BaseType::Structure, span)
            type.name = .consume(TokenType::Identifier).text
        }
        TokenType::Fn => {
            .consume(TokenType::Fn)
            .consume(TokenType::OpenParen)
            let params = Vector::new()
            while not .token_is(TokenType::CloseParen) {
                let param_type = .parse_type()
                // No names for parameters needed for function types
                params.push(Variable::new("", param_type, param_type.span))
                if not .token_is(TokenType::CloseParen) {
                    .consume(TokenType::Comma)
                }
            }
            .consume(TokenType::CloseParen)
            let return_type: &Type
            if .consume_if(TokenType::Colon) {
                return_type = .parse_type()
            } else {
                return_type = Type::new(BaseType::Void, .token().span)
            }
            type = Type::new(BaseType::Function, span.join(.token().span))
            type.params = params
            type.return_type = return_type
        }
        TokenType::OpenSquare => {
            .consume(TokenType::OpenSquare)

            type = Type::new(BaseType::Array, span)
            .parse_type_with_parent(type)

            .consume(TokenType::Semicolon)
            type.size_expr = .parse_expression(end_type: TokenType::CloseSquare)

            type.span = type.span.join(.token().span)
            .consume(TokenType::CloseSquare)
        }
        else => {
            .unhandled_type("parse_type")
            type = Type::new(BaseType::Error, .token().span)
        }
    }

    if parent? {
        parent.ptr = type
        parent.span = parent.span.join(type.span)
    }
    return type
}

def Parser::parse_type(&this): &Type => .parse_type_with_parent(null)

def Parser::parse_format_string(&this): &AST {
    let fstr = .consume(TokenType::FormatStringLiteral)
    let fstr_len = fstr.text.len()

    let expr_parts = Vector::new()    // Vector<string>
    let expr_start = Vector::new()    // Vector<i32>

    let format_parts = Vector::new()  // Vector<string>
    let specifiers = Vector::new()    // Vector<string>

    let count = 0
    let cur_start = 0
    let specifier_loc = -1

    for let i = 0; i < fstr_len; i += 1 {
        if fstr.text[i] == '{' and fstr.text[i - 1] != '\\' {
            if count == 0 {
                let part = fstr.text.substring(cur_start, i - cur_start)
                format_parts.push(part)
                cur_start = i + 1
            }
            count += 1
        } else if fstr.text[i] == '}' and fstr.text[i - 1] != '\\' {
            count -= 1
            if count == 0 {
                if specifier_loc > 0 {
                    let part = fstr.text.substring(cur_start, specifier_loc - cur_start)
                    expr_parts.push(part)
                    expr_start.push((fstr.text + cur_start))

                    specifier_loc += 1
                    while specifier_loc < i and fstr.text[specifier_loc] == ' ' {
                        specifier_loc += 1
                    }

                    if specifier_loc == i {
                        let loc = fstr.span.start;
                        loc.col += specifier_loc + 1
                        let span = Span(loc, loc)
                        .error(Error::new(span, "Expected format specifier"))
                        return null
                    }

                    let spec = fstr.text.substring(specifier_loc, i - specifier_loc)
                    specifiers.push(spec)
                } else {
                    let part = fstr.text.substring(cur_start, i - cur_start)
                    expr_parts.push(part)
                    expr_start.push((fstr.text + cur_start))
                    specifiers.push(null)
                }
                cur_start = i + 1
                specifier_loc = -1

            } else if count < 0 {
                .error(Error::new(fstr.span, "Unmatched '}' in format string"))
                return null
            }

        // FIXME: Should this use semicolons?
        } else if fstr.text[i] == ':' and fstr.text[i - 1] != '\\' {
            // TODO: Handle errors properly
            if count == 1 and fstr.text[i - 1] != ':' and fstr.text[i + 1] != ':' {
                specifier_loc = i
            }
        }
    }
    if count != 0 {
        .error(Error::new(fstr.span, "Unmatched '{' in format string"))
        return null
    }
    let part = fstr.text.substring(cur_start, fstr_len - cur_start)
    format_parts.push(part)

    let node = AST::new(ASTType::FormatStringLiteral, fstr.span)
    node.u.fmt_str.parts = format_parts

    let fstr_start = fstr.span.start
    let expr_nodes = Vector::new()
    for let i = 0; i < expr_parts.size; i += 1 {
        let part = expr_parts.at(i) as string
        let start = (expr_start.at(i) as string) - fstr.text

        let lexer = Lexer::make(part, fstr_start.filename)
        lexer.loc = fstr_start
        lexer.loc.col += start + 1

        let tokens = lexer.lex()
        for let i = 0; i < lexer.errors.size; i += 1 {
            .error(lexer.errors.at(i))
        }
        lexer.errors.free()

        .push_context(tokens)
        let expr = .parse_expression(end_type: TokenType::CloseCurly)
        if not .token_is(TokenType::EOF) {
            .error(Error::new(expr.span, "Invalid expression in format string"))
        }
        .pop_context()

        expr_nodes.push(expr)
    }
    node.u.fmt_str.exprs = expr_nodes
    node.u.fmt_str.specs = specifiers
    expr_parts.free()
    expr_start.free()
    return node
}

def Parser::parse_literal_suffix_type(&this, suffix: &Token): &Type {
    if not suffix? return null

    // FIXME: This feels like a hack, there much be a better way to do this.

    let tokens = Vector::new()
    tokens.push(suffix)
    tokens.push(.tokens.back()) // EOF from current file

    .push_context(tokens)
    let type = .parse_type()

    if not .token_is(TokenType::EOF) {
        let loc = .token().span.start
        let span = Span(loc, loc)
        .error(Error::new(span, "Invalid type suffix"))
    }

    .pop_context()
    tokens.free()

    return type
}

def Parser::parse_factor(&this, end_type: TokenType): &AST {
    let node = null as &AST

    match .token().type {
        TokenType::FormatStringLiteral => node = .parse_format_string()
        TokenType::IntLiteral => {
            node = AST::new(ASTType::IntLiteral, .token().span)
            let tok = .consume(TokenType::IntLiteral)
            node.u.num_literal = NumLiteral(
                text: tok.text,
                suffix: .parse_literal_suffix_type(tok.suffix)
            )
        }
        TokenType::FloatLiteral => {
            node = AST::new(ASTType::FloatLiteral, .token().span)
            let tok = .consume(TokenType::FloatLiteral)
            node.u.num_literal = NumLiteral(
                text: tok.text,
                suffix: .parse_literal_suffix_type(tok.suffix)
            )
        }
        TokenType::StringLiteral => {
            node = AST::new(ASTType::StringLiteral, .token().span)
            let tok = .consume(TokenType::StringLiteral)
            node.u.string_literal = tok.text
        }
        TokenType::CharLiteral => {
            node = AST::new(ASTType::CharLiteral, .token().span)
            let tok = .consume(TokenType::CharLiteral)
            node.u.char_literal = tok.text
        }
        TokenType::True | TokenType::False => {
            let tok = .consume(.token().type)
            node = AST::new(ASTType::BoolLiteral, tok.span)
            node.u.bool_literal = (tok.type == TokenType::True)
        }
        TokenType::Null => {
            node = AST::new(ASTType::Null, .token().span)
            .consume(TokenType::Null)
        }
        TokenType::Dot => {
            let op = .consume(TokenType::Dot)

            let lhs = AST::new(ASTType::Identifier, op.span)
            lhs.u.ident.name = "this"
            lhs.u.ident.is_function = false

            let rhs = if .token_is(TokenType::Identifier) {
                let name = .consume(TokenType::Identifier)
                let tmp = AST::new(ASTType::Identifier, name.span)
                tmp.u.ident.name = name.text
                yield tmp
            } else {
                .error(Error::new(op.span, "Expected identifier after '.'"))
                yield AST::new(ASTType::Error, op.span)
            }

            node = AST::new(ASTType::Member, lhs.span.join(rhs.span))
            node.u.member.lhs = lhs
            node.u.member.rhs = rhs
        }
        TokenType::Minus => {
            let op = .consume(TokenType::Minus)
            let expr = .parse_factor(end_type)
            node = AST::new_unop(ASTType::UnaryMinus, op.span.join(expr.span), expr)
        }
        TokenType::Not => {
            let op = .consume(TokenType::Not)
            let expr = .parse_factor(end_type)
            node = AST::new_unop(ASTType::Not, op.span.join(expr.span), expr)
        }
        TokenType::Tilde => {
            let op = .consume(TokenType::Tilde)
            let expr = .parse_factor(end_type)
            node = AST::new_unop(ASTType::BitwiseNot, op.span.join(expr.span), expr)
        }
        TokenType::Ampersand => {
            let op = .consume(TokenType::Ampersand)
            let expr = .parse_factor(end_type)
            node = AST::new_unop(ASTType::Address, op.span.join(expr.span), expr)
        }
        TokenType::Star => {
            let op = .consume(TokenType::Star)
            let expr = .parse_factor(end_type)
            node = AST::new_unop(ASTType::Dereference, op.span.join(expr.span), expr)
        }
        TokenType::Identifier => {
            let op = .consume(TokenType::Identifier)
            node = AST::new(ASTType::Identifier, op.span)
            node.u.ident.name = op.text
        }
        TokenType::OpenParen => {
            let open = .consume(TokenType::OpenParen)
            node = .parse_expression(end_type: TokenType::CloseParen)
            let close = .consume(TokenType::CloseParen)
            node.span = open.span.join(close.span)
        }
        TokenType::SizeOf => {
            let start = .consume(TokenType::SizeOf)
            .consume(TokenType::OpenParen)
            let type = .parse_type()
            let close = .consume(TokenType::CloseParen)
            node = AST::new(ASTType::SizeOf, start.span.join(close.span))
            node.u.size_of_type = type
        }

        // FIXME: Should this go here?
        TokenType::Match => node = .parse_match()
        TokenType::If => node = .parse_if()

        else => {
            .unhandled_type("parse_expression")
            node = AST::new(ASTType::Error, .token().span)
            .curr += 1
        }
    }

    let running = true
    while running {
        if .token_is(end_type) break
        match .token().type {
            TokenType::OpenParen => {
                .consume(TokenType::OpenParen)
                let args = Vector::new()
                while not .token_is(TokenType::CloseParen) {
                    let label = null as &AST
                    let expr = .parse_expression(end_type: TokenType::Comma)
                    if expr.type == ASTType::Identifier and .token_is(TokenType::Colon) {
                        .consume(TokenType::Colon)
                        label = expr
                        expr = .parse_expression(end_type: TokenType::Comma)
                    }

                    args.push(Argument::new(label, expr))
                    if not .token_is(TokenType::CloseParen) {
                        .consume(TokenType::Comma)
                    }
                }

                let end = .consume(TokenType::CloseParen)
                let call_type = ASTType::Call
                let call = AST::new(call_type, node.span.join(end.span))
                call.u.call.callee = node
                call.u.call.args = args
                call.u.call.added_method_arg = false
                node = call
            }
            TokenType::OpenSquare => {
                .consume(TokenType::OpenSquare)
                let index = .parse_expression(end_type: TokenType::CloseSquare)
                .consume(TokenType::CloseSquare)
                node = AST::new_binop(ASTType::Index, node, index)
            }
            TokenType::Dot => {
                let dot = .consume(TokenType::Dot)
                let rhs = if .token_is(TokenType::Identifier) {
                    let name = .consume(TokenType::Identifier)
                    let tmp = AST::new(ASTType::Identifier, name.span)
                    tmp.u.ident.name = name.text
                    yield tmp
                } else {
                    .error(Error::new(.token().span, "Expected identifier after '.'"))
                    yield AST::new(ASTType::Error, dot.span)
                }

                let member = AST::new(ASTType::Member, node.span.join(rhs.span))
                member.u.member.lhs = node
                member.u.member.rhs = rhs
                node = member
            }
            TokenType::ColonColon => {
                .consume(TokenType::ColonColon)
                let name = .consume(TokenType::Identifier)
                let member = AST::new(ASTType::ScopeLookup, node.span.join(name.span))

                let rhs = AST::new(ASTType::Identifier, name.span)
                rhs.u.ident.name = name.text

                member.u.member.lhs = node
                member.u.member.rhs = rhs
                node = member
            }
            TokenType::As => {
                .consume(TokenType::As)
                let type = .parse_type()
                let cast = AST::new(ASTType::Cast, node.span.join(type.span))
                cast.u.cast.lhs = node
                cast.u.cast.to = type
                node = cast
            }
            TokenType::Question => {
                .consume(TokenType::Question)
                node = AST::new_unop(ASTType::IsNotNull, node.span.join(.token().span), node)
            }

            else => running = false
        }
    }

    return node
}

def Parser::parse_term(&this, end_type: TokenType): &AST {
    let lhs = .parse_factor(end_type)
    while .token_is(TokenType::Star) or
            .token_is(TokenType::Slash) or
            .token_is(TokenType::Percent) {
        if .token_is(end_type) break
        let op = ASTType::from_token(.token().type)
        .curr += 1
        let rhs = .parse_factor(end_type)
        lhs = AST::new_binop(op, lhs, rhs)
    }
    return lhs
}

def Parser::parse_additive(&this, end_type: TokenType): &AST {
    let lhs = .parse_term(end_type)
    while .token_is(TokenType::Plus) or .token_is(TokenType::Minus) {
        if .token_is(end_type) break
        let op = ASTType::from_token(.token().type)
        .curr += 1
        let rhs = .parse_term(end_type)
        lhs = AST::new_binop(op, lhs, rhs)
    }
    return lhs
}

def Parser::parse_shift(&this, end_type: TokenType): &AST {
    let lhs = .parse_additive(end_type)
    while .token_is(TokenType::LessThanLessThan) or
            .token_is(TokenType::GreaterThanGreaterThan) {
        if .token_is(end_type) break
        let op = ASTType::from_token(.token().type)
        .curr += 1
        let rhs = .parse_additive(end_type)
        lhs = AST::new_binop(op, lhs, rhs)
    }
    return lhs
}

def Parser::parse_bw_and(&this, end_type: TokenType): &AST {
    let lhs = .parse_shift(end_type)
    while .token_is(TokenType::Ampersand) {
        if .token_is(end_type) break
        let op = ASTType::from_token(.token().type)
        .curr += 1
        let rhs = .parse_shift(end_type)
        lhs = AST::new_binop(op, lhs, rhs)
    }
    return lhs
}

def Parser::parse_bw_xor(&this, end_type: TokenType): &AST {
    let lhs = .parse_bw_and(end_type)
    while .token_is(TokenType::Caret) {
        if .token_is(end_type) break
        let op = ASTType::from_token(.token().type)
        .curr += 1
        let rhs = .parse_bw_and(end_type)
        lhs = AST::new_binop(op, lhs, rhs)
    }
    return lhs
}

def Parser::parse_bw_or(&this, end_type: TokenType): &AST {
    let lhs = .parse_bw_xor(end_type)
    while .token_is(TokenType::Line) {
        if .token_is(end_type) break
        let op = ASTType::from_token(.token().type)
        .curr += 1
        let rhs = .parse_bw_xor(end_type)
        lhs = AST::new_binop(op, lhs, rhs)
    }
    return lhs
}

def Parser::parse_relational(&this, end_type: TokenType): &AST {
    let operands = Vector::new()
    let operators = Vector::new()

    operands.push(.parse_bw_or(end_type))
    while .token_is(TokenType::LessThan) or
            .token_is(TokenType::GreaterThan) or
            .token_is(TokenType::LessThanEquals) or
            .token_is(TokenType::GreaterThanEquals) or
            .token_is(TokenType::EqualEquals) or
            .token_is(TokenType::NotEquals) {
        if .token_is(end_type) break
        operators.push(.token())
        .curr += 1
        let term = .parse_bw_or(end_type)
        operands.push(term)
    }

    if operators.size == 0 then return operands.at(0)

    let root = null as &AST
    for let i = 0; i < operators.size; i += 1 {
        let tok = operators.at(i) as &Token
        let lhs = operands.at(i) as &AST
        let rhs = operands.at(i+1) as &AST
        let op = AST::new_binop(ASTType::from_token(tok.type), lhs, rhs)
        if root? {
            root = AST::new_binop(ASTType::And, root, op)
        } else {
            root = op
        }
    }

    operands.free()
    operators.free()

    return root
}

def Parser::parse_logical_and(&this, end_type: TokenType): &AST {
    let lhs = .parse_relational(end_type)
    while .token_is(TokenType::And) {
        if .token_is(end_type) break
        let op = ASTType::from_token(.token().type)
        .curr += 1
        let rhs = .parse_relational(end_type)
        lhs = AST::new_binop(op, lhs, rhs)
    }
    return lhs
}

def Parser::parse_logical_or(&this, end_type: TokenType): &AST {
    let lhs = .parse_logical_and(end_type)
    while .token_is(TokenType::Or) {
        if .token_is(end_type) break
        let op = ASTType::from_token(.token().type)
        .curr += 1
        let rhs = .parse_logical_and(end_type)
        lhs = AST::new_binop(op, lhs, rhs)
    }
    return lhs
}

def Parser::parse_expression(&this, end_type: TokenType): &AST {
    let lhs = .parse_logical_or(end_type)
    while .token_is(TokenType::Equals) or
            .token_is(TokenType::PlusEquals) or
            .token_is(TokenType::MinusEquals) or
            .token_is(TokenType::StarEquals) or
            .token_is(TokenType::SlashEquals) {
        if .token_is(end_type) break
        let op = ASTType::from_token(.token().type)
        .curr += 1
        let rhs = .parse_expression(end_type)
        lhs = AST::new_binop(op, lhs, rhs)
    }
    return lhs
}

def Parser::parse_match(&this): &AST {
    let op = .consume(TokenType::Match)
    let expr = .parse_expression(end_type: TokenType::OpenCurly)
    let node = AST::new(ASTType::Match, op.span.join(expr.span))
    node.u.match_stmt.expr = expr

    let cases = Vector::new()
    .consume(TokenType::OpenCurly)
    while not .token_is(TokenType::CloseCurly) {
        if .token_is(TokenType::Else) {
            node.u.match_stmt.defolt_span = .token().span
            .consume(TokenType::Else)
            .consume(TokenType::FatArrow)
            node.u.match_stmt.defolt = .parse_statement()

        } else {
            let cond = .parse_factor(TokenType::Line)
            let body = null as &AST
            if not .consume_if(TokenType::Line) {
                .consume(TokenType::FatArrow)
                body = .parse_statement()
                if not .token_is(TokenType::CloseCurly) {
                    .consume_newline_or(TokenType::Comma)
                }
            }
            let _case = MatchCase::new(cond, body)
            cases.push(_case)
        }
    }
    node.span = op.span.join(.token().span)
    .consume(TokenType::CloseCurly)
    node.u.match_stmt.cases = cases

    return node
}

def Parser::parse_if(&this): &AST {
    let start_span = .token().span
    .consume(TokenType::If)
    let cond = .parse_expression(end_type: TokenType::Newline)
    .consume_if(TokenType::Then)
    let body = .parse_statement()

    let end_span = body.span
    let els = null as &AST
    if .consume_if(TokenType::Else) {
        els = .parse_statement()
        end_span = els.span
    }
    let node = AST::new(ASTType::If, start_span.join(end_span))
    node.u.if_stmt.cond = cond
    node.u.if_stmt.body = body
    node.u.if_stmt.els = els
    return node
}

def Parser::consume_end_of_statement(&this) {
    if .token_is(TokenType::CloseCurly) return
    .consume_newline_or(TokenType::Semicolon)
}

def Parser::parse_statement(&this): &AST {
    let node = null as &AST
    let start_span = .token().span

    match .token().type {
        TokenType::Match => node = .parse_match()
        TokenType::If => node = .parse_if()
        TokenType::OpenCurly => node = .parse_block()
        TokenType::Return => {
            .consume(TokenType::Return)
            let expr = null as &AST
            if not .token().seen_newline {
                expr = .parse_expression(end_type: TokenType::Newline)
            }
            node = AST::new_unop(ASTType::Return, start_span.join(.token().span), expr)
            .consume_end_of_statement()
        }
        TokenType::Break => {
            node = AST::new(ASTType::Break, start_span)
            .consume(TokenType::Break)
            .consume_end_of_statement()
        }
        TokenType::Continue => {
            .consume(TokenType::Continue)
            node = AST::new(ASTType::Continue, start_span)
            .consume_end_of_statement()
        }
        TokenType::Defer => {
            .consume(TokenType::Defer)
            let expr = .parse_statement()
            node = AST::new_unop(ASTType::Defer, start_span.join(expr.span), expr)
        }
        TokenType::Yield => {
            .consume(TokenType::Yield)
            let expr = .parse_expression(end_type: TokenType::Newline)
            node = AST::new_unop(ASTType::Yield, start_span.join(expr.span), expr)
            .consume_end_of_statement()
        }
        TokenType::While => {
            .consume(TokenType::While)
            let cond = .parse_expression(end_type: TokenType::Newline)
            let body = .parse_statement()
            node = AST::new(ASTType::While, start_span.join(body.span))
            node.u.loop.cond = cond
            node.u.loop.body = body
        }
        TokenType::For => {
            node = AST::new(ASTType::For, .token().span)
            .consume(TokenType::For)

            if not .token_is(TokenType::Semicolon) {
                let init = .parse_statement()
                // FIXME: This doesn't seem very robust...
                if init.type != ASTType::Assignment and
                    init.type != ASTType::VarDeclaration {
                    .error(Error::new(init.span, "Invalid for loop initializer"))
                }
                node.u.loop.init = init

                // This is a hack
                let prev = .tokens.at(.curr - 1) as &Token
                if prev.type == TokenType::Semicolon { .curr -= 1; }
            }
            .consume(TokenType::Semicolon)
            if not .token_is(TokenType::Semicolon)
                node.u.loop.cond = .parse_expression(end_type: TokenType::Semicolon)
            .consume(TokenType::Semicolon)

            // FIXME: Should we always require a curly?
            if not .token_is(TokenType::CloseCurly)
                node.u.loop.incr = .parse_expression(end_type: TokenType::Newline)

            node.u.loop.body = .parse_statement()
            node.span = node.span.join(node.u.loop.body.span)
        }
        TokenType::Let => {
            .consume(TokenType::Let)
            let name = .consume(TokenType::Identifier)
            let end_span = name.span

            let type = null as &Type
            if .consume_if(TokenType::Colon) {
                type = .parse_type()
                end_span = type.span
            }
            let init = null as &AST
            if .consume_if(TokenType::Equals) {
                init = .parse_expression(end_type: TokenType::Newline)
                end_span = init.span
            }
            .consume_end_of_statement()

            node = AST::new(ASTType::VarDeclaration, start_span.join(end_span))
            node.u.var_decl.var = Variable::new(name.text, type, name.span)
            node.u.var_decl.init = init
        }
        TokenType::Const => {
            .error(Error::new(.token().span, "Const declarations are only allowed in the global scope"))
        }
        else => {
            node = .parse_expression(end_type: TokenType::Newline)
            .consume_if(TokenType::Semicolon)
        }
    }

    return node
}

def Parser::parse_block(&this): &AST {
    let node = AST::new(ASTType::Block, .token().span)
    .consume(TokenType::OpenCurly)

    let statements = Vector::new()
    while not .token_is(TokenType::CloseCurly) {
        let statement = .parse_statement()
        statements.push(statement)
    }
    node.u.block.statements = statements

    .consume(TokenType::CloseCurly)
    return node
}

def Parser::parse_function(&this): &Function {
    .consume(TokenType::Def)

    let struct_type = null as &Type
    let struct_name = null as string
    let is_method = false
    let is_static = false

    // Handle methods
    let next_token = .tokens.at(.curr + 1) as &Token
    if next_token.type == TokenType::ColonColon {
        struct_type = .parse_type()
        if not struct_type.name? {
            .error(Error::new(struct_type.span, "Invalid type in method declaration"))
        }
        struct_name = struct_type.name
        is_method = true
        .consume(TokenType::ColonColon)
    }

    let name = .consume(TokenType::Identifier)

    let func = Function::new(name.span)
    func.name = name.text
    func.is_method = is_method
    func.method_struct_name = struct_name

    .consume(TokenType::OpenParen)
    while not .token_is(TokenType::CloseParen) {
        let found_amp = .consume_if(TokenType::Ampersand)
        let var_name = .consume(TokenType::Identifier)
        let type = null as &Type
        if func.params.empty() and is_method {
            if var_name.text.eq("this") {
                type = struct_type
                if found_amp {
                    type = Type::new_link(BaseType::Pointer, type, name.span)
                }
            } else if found_amp {
                .error(Error::new(var_name.span, "Expected 'this' over here"))
            } else {
                is_static = true
            }
        }
        if not type? {
            .consume(TokenType::Colon)
            type = .parse_type()
        }
        let var = Variable::new(var_name.text, type, var_name.span)
        func.params.push(var)

        if not .token_is(TokenType::CloseParen) {
            .consume(TokenType::Comma)
        }
    }
    .consume(TokenType::CloseParen)
    if is_method and func.params.size == 0 {
        is_static = true
    }
    func.is_static = is_static

    if .consume_if(TokenType::Colon) {
        func.return_type = .parse_type()
    } else if name.text.eq("main") {
        func.return_type = Type::new(BaseType::I32, name.span)
    } else {
        func.return_type = Type::new(BaseType::Void, name.span)
        if .token_is(TokenType::Identifier) and .token().text.eq("exits") {
            .consume(TokenType::Identifier)
            func.exits = true
        }
    }

    if .consume_if(TokenType::Extern) {
        func.is_extern = true
        func.extern_name = func.name
        if .consume_if(TokenType::OpenParen) {
            let name = .consume(TokenType::StringLiteral)
            func.extern_name = name.text
            .consume(TokenType::CloseParen)
        }
    } else if .consume_if(TokenType::FatArrow) {
        func.is_arrow = true
        let expr = .parse_expression(TokenType::Newline)
        if not .token().seen_newline {
            let end_loc = Span(expr.span.end, expr.span.end)
            .error(Error::new(end_loc, "Expected newline after arrow function"))
        }
        let ret_stmt = AST::new_unop(ASTType::Return, expr.span, expr)
        func.body = ret_stmt

    } else {
        func.is_extern = false
        func.body = .parse_block()
    }

    return func
}

def Parser::parse_enum(&this): &Structure {
    let start_span = .consume(TokenType::Enum).span
    let name = .consume(TokenType::Identifier)

    let enum_def = Structure::new(start_span.join(name.span))
    enum_def.name = name.text
    enum_def.is_enum = true

    let type = Type::new(BaseType::Structure, name.span)
    enum_def.type = type
    type.name = name.text
    type.struct_def = enum_def

    if .consume_if(TokenType::Extern) {
        enum_def.is_extern = true
        enum_def.extern_name = enum_def.name
        if .consume_if(TokenType::OpenParen) {
            let name = .consume(TokenType::StringLiteral)
            enum_def.extern_name = name.text
            .consume(TokenType::CloseParen)
        }
    }

    .consume(TokenType::OpenCurly)
    while not .token_is(TokenType::CloseCurly) {
        let name = .consume(TokenType::Identifier)
        let type = Type::new(BaseType::I32, name.span)

        let var = Variable::new(name.text, type, name.span)

        // Enforce extern enums to have all values defined
        if enum_def.is_extern {
            .consume(TokenType::Equals)
            .consume(TokenType::Extern)
            .consume(TokenType::OpenParen)
            let name = .consume(TokenType::StringLiteral)
            .consume(TokenType::CloseParen)
            var.extern_name = name.text
            var.is_extern = true
        }

        enum_def.fields.push(var)
        if not .token_is(TokenType::CloseCurly) {
            .consume_newline_or(TokenType::Comma)
        }
    }
    .consume(TokenType::CloseCurly)

    return enum_def
}

def Parser::parse_struct(&this): &Structure {
    let is_union = false
    let start_span = .token().span
    if .consume_if(TokenType::Union) {
        is_union = true
    } else {
        .consume(TokenType::Struct)
    }

    let name = .consume(TokenType::Identifier)

    let struc = Structure::new(start_span.join(name.span))
    struc.name = name.text

    if .consume_if(TokenType::Extern) {
        struc.is_extern = true
        struc.extern_name = struc.name
        if .consume_if(TokenType::OpenParen) {
            let name = .consume(TokenType::StringLiteral)
            struc.extern_name = name.text
            .consume(TokenType::CloseParen)
        }
    }

    // Extern structs don't need to have a body.
    if not struc.is_extern or .token_is(TokenType::OpenCurly) {
        .consume(TokenType::OpenCurly)
        while not .token_is(TokenType::CloseCurly) {
            let name = .consume(TokenType::Identifier)
            .consume(TokenType::Colon)
            let type = .parse_type()

            let var = Variable::new(name.text, type, name.span)
            struc.fields.push(var)
            if not .token_is(TokenType::CloseCurly) {
                .consume_newline_or(TokenType::Comma)
            }
        }
        .consume(TokenType::CloseCurly)
    }

    let type = Type::new(BaseType::Structure, name.span)
    type.name = name.text
    struc.type     = type
    type.struct_def  = struc
    struc.is_union = is_union

    return struc
}

def Parser::parse_global_value(&this, is_constant: bool): &AST {
    let start_token = if is_constant {
        yield .consume(TokenType::Const)
    } else {
        yield .consume(TokenType::Let)
    }

    let node = AST::new(ASTType::VarDeclaration, .token().span)
    let name = if .token_is(TokenType::Identifier) {
        yield .consume(TokenType::Identifier)
    } else {
        .error(Error::new(.token().span, "Expected identifier"))
        return node
    }

    let type = null as &Type
    if .consume_if(TokenType::Colon) { type = .parse_type(); }

    let var = Variable::new(name.text, type, name.span)
    node.u.var_decl.var = var

    if .consume_if(TokenType::Extern) {
        var.is_extern = true
        if .consume_if(TokenType::OpenParen) {
            let name = .consume(TokenType::StringLiteral)
            var.extern_name = name.text
            .consume(TokenType::CloseParen)
        } else {
            var.extern_name = var.name
        }

        if not type? {
            .error(Error::new(name.span, "Extern values must have a type specified"))
        }
    } else {
        var.is_extern = false
        if .consume_if(TokenType::Equals) {
            node.u.var_decl.init = .parse_expression(end_type: TokenType::Newline)
        }
    }
    .consume_newline_or(TokenType::Semicolon)
    return node
}

def Parser::find_file_path(&this, filename: string): string {
    // Absolute paths
    if filename.starts_with("/") return filename

    // Relative to project root
    if filename.starts_with("@/") {
        let file_path = `{.project_root}/{filename + 2}` // Remove @/
        if File::exists(file_path)
            return file_path
        free(file_path)

    // If unspecified, check include paths (which also includes working directory)
    } else {
        for let i = 0; i < .include_dirs.size; i += 1 {
            let dir = .include_dirs.at(i) as string

            let file_path = `{dir}/{filename}`
            if File::exists(file_path)
                return file_path
            free(file_path)
        }
    }

    // This only happens if lib/prelude.ae is not found
    if .curr == 0 {
        println("---------------------------------------------------------------")
        println("[-] Error: Could not find file '%s'", filename)
        println("[+] Hint: Specify the aecor root directory with the -l option")
        println("---------------------------------------------------------------")
        exit(1)
    }

    .curr -= 1
    .error(Error::new(.token().span, `Could not find file: {filename}`))
    exit(1)
}

def Parser::include_file(&this, program: &Program, filename: string): string {
    filename = .find_file_path(filename)
    if program.is_file_included(filename)
        return filename
    program.add_included_file(filename)

    let file = File::open(filename, "r")
    let contents = file.slurp()

    let lexer = Lexer::make(contents, filename)
    let tokens = lexer.lex()

    for let i = 0; i < lexer.errors.size; i += 1 {
        .error(lexer.errors.at(i))
    }
    lexer.errors.free()

    .push_context(tokens)
    .parse_into_program(program)
    .pop_context()
    return filename
}

def Parser::parse_use(&this, program: &Program) {
    .consume(TokenType::Use)
    let name = .consume(TokenType::StringLiteral)
    .consume_newline_or(TokenType::Semicolon)
    .include_file(program, name.text)
}


def Parser::parse_compiler_option(&this, program: &Program) {
    .consume(TokenType::AtSign)
    let compiler = .consume(TokenType::Identifier)
    if not compiler.text.eq("compiler") {
        .error(Error::new(compiler.span, "Expected 'compiler'"))
    }

    let name = .consume(TokenType::Identifier)
    match name.text {
        "c_include" => {
            let filename = .consume(TokenType::StringLiteral)
            program.c_includes.push(filename.text)
        }
        "c_flag" => {
            let flag = .consume(TokenType::StringLiteral)
            program.c_flags.push(flag.text)
        }
        "c_embed_header" => {
            let filename = .consume(TokenType::StringLiteral)
            let resolved = .find_file_path(filename.text)
            program.c_embed_headers.push(resolved)
        }
        else => .error(Error::new(name.span, "Unknown compiler option"))
    }
}

def Parser::parse_into_program(&this, program: &Program) {
    while not .token_is(TokenType::EOF) {
        match .token().type {
            TokenType::Use => .parse_use(program)
            TokenType::AtSign => .parse_compiler_option(program)
            TokenType::Def => {
                let func = .parse_function()
                program.functions.push(func)
            }
            TokenType::Let => {
                let node = .parse_global_value(is_constant: false)
                program.global_vars.push(node)
            }
            TokenType::Const => {
                let node = .parse_global_value(is_constant: true)
                program.constants.push(node)
            }
            TokenType::Struct | TokenType::Union => {
                let structure = .parse_struct()
                program.structures.push(structure)
            }
            TokenType::Enum => {
                let structure = .parse_enum()
                program.structures.push(structure)
            }
            else =>.unhandled_type("parse_program")
        }
    }
}

def Parser::include_prelude(&this, program: &Program) {
    .program = program
    .include_file(program, "lib/prelude.ae")
}

