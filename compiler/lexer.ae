use "lib/vector.ae"
use "@/tokens.ae"

@compiler c_include "ctype.h"
def is_alpha(c: char): bool extern("isalpha")
def is_digit(c: char): bool extern("isdigit")
def is_alnum(c: char): bool extern("isalnum")

struct Lexer {
    source: string
    source_len: i32
    i: i32
    loc: Location
    seen_newline: bool
    tokens: &Vector
}

def Lexer::make(source: string, filename: string): Lexer {
    let lexer: Lexer
    lexer.source = source
    lexer.source_len = source.len()
    lexer.i = 0
    lexer.loc = Location::make(filename, 1, 1)
    lexer.seen_newline = false
    lexer.tokens = Vector::new()
    return lexer
}

def Lexer::push(&this, token: &Token) {
    token.seen_newline = .seen_newline
    .tokens.push(token)
    .seen_newline = false
}

def Lexer::push_type(&this, type: TokenType, len: i32) {
    let start_loc = .loc
    .loc.col += len
    .i += len
    .push(Token::from_type(type, Span::make(start_loc, .loc)))
}

def Lexer::peek(&this, offset: i32): char {
    if .source[.i] == '\0' {
        return .source[.i]
    }
    return .source[.i + 1]
}

def Lexer::lex_char_literal(&this) {
    let start_loc = .loc
    let start = .i + 1
    .i += 1

    if .source[.i] == '\\' {
        .i += 2
    } else {
        .i += 1
    }
    if .source[.i] != '\'' {
        .loc.col += .i - start + 1
        error_loc(.loc, "Expected ' after character literal")
    }

    let len = .i - start
    let text = .source.substring(start, len)

    .loc.col += len + 2;
    .i += 1
    .push(Token::new(TokenType::CharLiteral, Span::make(start_loc, .loc), text))
}

def Lexer::lex_string_literal(&this) {
    let start_loc = .loc
    let end_char = .source[.i]
    let start = .i + 1;
    .i += 1
    while (.source[.i] != end_char) {
        if (.source[.i] == '\\') {
            .i += 1
        }
        .i += 1
    }

    let len = .i - start
    let text = .source.substring(start, len)
    .loc.col += len + 2;
    .i += 1
    if end_char == '`' {
        .push(Token::new(TokenType::FormatStringLiteral, Span::make(start_loc, .loc), text))
    } else {
        .push(Token::new(TokenType::StringLiteral, Span::make(start_loc, .loc), text))
    }
}

def Lexer::lex(&this): &Vector {
    while .i < .source_len {
        let c = .source[.i]
        match c {
            ' ' | '\t' | '\v' | '\r' | '\b' => {
                .loc.col += 1
                .i += 1
            }
            '\n' => {
                .loc.line += 1
                .loc.col = 1
                .i += 1
                .seen_newline = true
            }
            ';' => .push_type(TokenType::Semicolon, 1)
            ',' => .push_type(TokenType::Comma, 1)
            '.' => .push_type(TokenType::Dot, 1)
            '(' => .push_type(TokenType::OpenParen, 1)
            ')' => .push_type(TokenType::CloseParen, 1)
            '[' => .push_type(TokenType::OpenSquare, 1)
            ']' => .push_type(TokenType::CloseSquare, 1)
            '{' => .push_type(TokenType::OpenCurly, 1)
            '}' => .push_type(TokenType::CloseCurly, 1)
            '@' => .push_type(TokenType::AtSign, 1)
            '%' => .push_type(TokenType::Percent, 1)
            '^' => .push_type(TokenType::Caret, 1)
            '&' => .push_type(TokenType::Ampersand, 1)
            '|' => .push_type(TokenType::Line, 1)
            '!' => match .peek(1) {
                '='  => .push_type(TokenType::NotEquals, 2)
                else => .push_type(TokenType::Exclamation, 1)
            }
            ':' => match .peek(1) {
                ':'  => .push_type(TokenType::ColonColon, 2)
                else => .push_type(TokenType::Colon, 1)
            }
            '=' => match .peek(1) {
                '='  => .push_type(TokenType::EqualEquals, 2)
                '>'  => .push_type(TokenType::FatArrow, 2)
                else => .push_type(TokenType::Equals, 1)
            }
            '*' => match .peek(1) {
                '='  => .push_type(TokenType::StarEquals, 2)
                else => .push_type(TokenType::Star, 1)
            }
            '+' => match .peek(1) {
                '='  => .push_type(TokenType::PlusEquals, 2)
                else => .push_type(TokenType::Plus, 1)
            }
            '-' => match .peek(1) {
                '='  => .push_type(TokenType::MinusEquals, 2)
                else => .push_type(TokenType::Minus, 1)
            }
            '<' => match .peek(1) {
                '='  => .push_type(TokenType::LessThanEquals, 2)
                else => .push_type(TokenType::LessThan, 1)
            }
            '>' => match .peek(1) {
                '='  => .push_type(TokenType::GreaterThanEquals, 2)
                else => .push_type(TokenType::GreaterThan, 1)
            }
            '/' => match .peek(1) {
                '/' => {
                    .i += 1
                    while .i < .source_len and .source[.i] != '\n' {
                        .i += 1
                    }
                }
                '='  => .push_type(TokenType::SlashEquals, 2)
                else => .push_type(TokenType::Slash, 1)
            }
            '\'' => .lex_char_literal()
            '"' | '`' => .lex_string_literal()
            else => {
                let start_loc = .loc

                if (is_digit(c)) {
                    let start = .i

                    let token_type: TokenType
                    while (is_digit(.source[.i])) {
                        .i += 1
                    }
                    if .source[.i] == '.' {
                        .i += 1
                        while (is_digit(.source[.i])) {
                            .i += 1
                        }
                        token_type = TokenType::FloatLiteral
                    } else {
                        token_type = TokenType::IntLiteral
                    }
                    let len = .i - start
                    let text = .source.substring(start, len)

                    .loc.col += len
                    .push(Token::new(token_type, Span::make(start_loc, .loc), text))

                } else if (is_alpha(c) or c == '_') {
                    let start = .i
                    while (is_alnum(.source[.i]) or .source[.i] == '_') {
                        .i += 1
                    }
                    let len = .i - start
                    let text = .source.substring(start, len)

                    .loc.col += len
                    .push(Token::from_ident(text, Span::make(start_loc, .loc)))

                } else {
                    println("%s: Unrecognized char in lexer: '%d'", .loc.str(), c)
                    exit(1)
                }
            }
        }
    }
    .push_type(TokenType::EOF, 0)
    return .tokens
}
